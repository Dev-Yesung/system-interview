# 처리율 제한장치

## 배경

```
현재 한국 시장에는 3개의 강력한 라이브 스트리밍 플랫폼이 존재한다.
외국기업이 운영하는 플랫폼 2개와 한국기업이 운영하는 플랫폼 1개이다.
이 중 트x치란 외국기업 플랫폼과 아프x카 라는 한국기업 플랫폼이 시장을 주도하고 있었다.

하지만 상황이 바뀌어, 트x치가 한국 시장에서 철수를 하게 되었고,
그 플랫폼과 계약을 맺은 다수의 인기 인터넷 방송인들이 자유계약으로 풀리게 되었다.
우리 회사는 빠른 시일 내에 많은 사용자를 수용할 수 있는 스트리밍 서비스를 구현해야 한다.

현재 우리와 계약을 맺은 스트리머는 중 가장 많은 사용자를 보유한 스트리머는 침x맨이다.
이 스트리머는 라이브 방송을 진행하게 되면, 
최소 1만 5천 명 ~ 최대 8만 5천 명의 시청자들이 서비스에 접속하게 된다.
따라서 이 스트리머가 안정적으로 방송할 수 있는 환경을 만든다면, 
나머지 스트리머들도 충분히 안정적으로 방송을 할 수 있을 것이다.

나는 이 신규 스트리밍 플랫폼 사업팀에 속한 백엔드 개발자이다. 
내게 맡겨진 임무는 라이브 스트리밍에 참여한 다수의 사용자들이 
불편함을 느끼지 않도록 실시간으로 채팅을 할 수 있게 만드는 것이다.

채팅 기능은 다 만들었지만, 사용자들에게 제약을 주는 것이 필요하다.
한 명 혹은 여러 명의 사용자가 짧은 시간 안에 채팅을 도배할 경우 
혹은 채팅 도배봇에 의해 채팅방이 도배될 경우 스트리머와 다른 사용자들에게 불편함을 줄 수 있다.
또한 빠른 시간 안에 다수의 데이터가 들어오게 되면 서버가 데이터를 감당하지 못하여 셧다운 될 수도 있다.

따라서 내가 지금 만들어야 하는 기능은 한 명의 사용자가 짧은 시간 안에 채팅으로 채팅방을 도배하는 것을 막는 것이다.
즉, 서버측에서 채팅 기능에 관한 처리율 제한장치를 만드는 것이 목표이다.
```

## 하드웨어 스팩

```
CPU 모델 : Intel(R) Xeon(R) Silver 4214
CPU 클럭 : 2.20GHz
CPU 아키텍처 : x86_64
CPU 개수 : 4개
CPU 코어 개수 : 12개 (총 48개 코어)
CPU 코어 당 스레드 개수 : 2개 (총 96개 스레드)
RAM : 376GB
보조 저장장치 : 5TB
```

## 요구사항

이 요구사항에서는 오직 도배를 방지하기 위한 요청횟수에만 집중하고 나머지 조건들은 무시한다.

```
1) 채팅방에 접속한 사용자 수는 최소 1만 5천명, 최대 8만 5천명이다.
2) 채팅 글자수 제한은 최소 1자, 최대 100자이다.
3) 서비스는 분산환경으로 설계되어 있다.
4) 가능한 한 적은 메모리를 사용해야 한다.
5) 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
6) 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주정서는 안된다.
```

## 설계

### 하드웨어 스팩과 비용 계산을 통한 정책결정

```
백엔드 서버 개발에 사용된 언어는 자바21이고 프레임워크는 스프링을 사용하였다.

자바에서 문자를 저장하는 방식은 UTF-16을 기본으로 한다. 따라서 한 글자에 2바이트를 차지하게 된다.
사용자들은 채팅에 이모지를 사용할 수 있는데 이모지 하나당 4바이트를 차지(두 글자로 취급)한다.
따라서 글자 길이에 따라 데이터량을 생각하는 것이 아니라 바이트에 따라 생각을 해야 한다.
이모지를 포함하여 100글자 제한이므로 최소 2바이트에서 최대 200바이트까지 가능하다.

만일 한 명의 사용자가 1초 동안 채팅방에 보낼 수 있는 채팅의 개수가 최대 5개라면, 대략 1000바이트 즉 1초에 1KB의 메모리를 서버가 받게 된다.
이를 최소 1만 5천 명 - 최대 8만 5천 명의 사용자가 1초에 5번의 채팅을 보낼 수 있다고 가정하면, 1초에 15MB ~ 85MB의 데이터를 서버에서 받게 된다.
이렇게 되면 GC가 작동하지 않았다는 전제하에 1분에 900MB ~ 5.1GB를 차지하게 된다.
(실제로 이 정도 부하를 받았을 때, JVM이 메모리 최적화를 얼마나 잘 할지는 부하 테스트를 해봐야 알수 있을거 같다.)
물론 RAM의 크기가 376GB이지만, 서버에서 사용하는 다른 자원들(시스템 자원, 모니터링 툴, 쿠버네티스 환경 등등)에 의해 메모리가 점유되는 것도 감안해야 한다.
이 정도 속도라면 빠르게 메모리가 고갈될 것이기 때문에 1초에 5번은 너무 많다. 따라서 반 정도인 1초에 2번까지만 허용하는 것으로 한다.

하지만 사용자가 정책을 파악하고 악의적으로 1초에 2번씩 딱 맞춰서 채팅 메시지를 보낸다면, 60초에 대략 120개의 메시지가 허용된다.
최소 1만 5천 명 ~ 최대 8만 5천 명의 사용자에게 이 가정을 도입하면, 대략 180만 개에서 1천만 20만 개의 채팅 메시지가 들어온다.
이 데이터를 압축 없이 저장한다고 가정하면 최소 3.43GB, 최대 19.46GB이다. 
이 스트리머가 주 5일 하루에 최대 6시간 방송을 한다고 가정하면, 하루에 1.21TB에서 6.84TB이다.
이렇게 된다면 겨우 채팅 데이터만으로 일주일에 6TB ~ 35TB를 차지하게 된다. 너무 많은 데이터를 차지하게 되므로 1분 내 채팅 개수에도 제한이 필요하다.
채팅이 가장 활발한 사용자를 기준으로 대략 10초에 3번의 메시지를 작성한다. 따라서 60초에 18번의 메시지를 허용하도록 한다.
그렇다면 현재 용량의 대략 3/20 수준으로 900GB ~ 5.25TB가 된다. 따라서 한 달에 1.6TB ~ 21TB 정도가 된다. 
이 정도면 HDD를 기준으로 한 달에 최대 80만원 정도의 스토리지 비용이 지출된다.

여기서 문자열 압축 알고리즘을 사용하여 용량을 줄일 수 있는데, 
일반적인 압축 알고리즘(LZ77 / LZ78 / LZW, bzip2, zstd)을 사용한다고 가정하면 5TB의 80% 정도 수준인 500GB 정도로 압축이 가능하다.
이 경우 한달에 10만원 정도의 비용이 들어가는 것이고 그 스트리머에 의해 수익이 창출되는 것을 감안하면 합리적이라 생각된다.

결론
1) 사용자 한 명은 1초에 최대 2번의 채팅 메시지를 보내는 것이 허용됨
2) 사용자 한 명은 1분에 최대 18번의 채팅 메시지를 보내는 것이 허용됨
```

### 처리율 제한 알고리즘

대중적으로 잘 알려진 처리율 제한 알고리즘은 아래와 같다.

```
1) token bucket algorithm
특징
: 용량이 N인 버킷에 토큰 공급기가 사전 설정된 양 만큼의 토큰을 주기적으로 채움
토큰이 꽉 찬 버킷에는 더 이상 토큰이 추가되지 않는다.
버킷의 크기(버킷에 담을 수 있는 토큰의 최대 개수)와 토큰 공급률(초당 몇 개의 토큰이 버킷에 공급되는가), 2개의 인자를 받는다.
버킷을 몇 개 사용하는가는 공급제한 규칙에 따라 달라진다.
- 보통 API 엔드포인트 마다 별도의 버킷을 둔다.
- IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당한다.
- 만일 시스템 처리율을 초당 10,000개 요청으로 제한한다면, 모든 요청이 하나의 버킷을 공유하도록 해야 한다.

장점
1) 구현이 쉽다.
2) 메모리 사용측면에서 효율적이다.
3) 짧은 시간에 집중되는 트래픽도 처리가 가능하다.

단점
: 버킷 크기와 토큰 공급률 인자를 적절하게 튜닝하는 것이 까다롭다.

2) leaky bucket algorithm
특징
: 토큰 버킷 알고리즘과 유사하지만 요청 처리율이 고정되어있다. 보통 FIFO QUEUE로 구현한다.
동작원리는 다음과 같다. 
1) 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
2) 큐가 가득 차 있는 경우에는 새 요청은 버린다.
3) 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

누출 버킷 알고리즘은 아래 두 가지 인자로 구성된다.
1) 버킷의 크기(Queue Size와 같은 값) 
2) 처리율(outflow rate, 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값)

장점:
1) 큐의 크기가 제한되어 있어, 메모리 사용량 측면에서 효율적이다.
2) 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우에 적합하다.

단점:
1) 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.
2) 두 개의 인자를 올바르게 튜닝하기가 까다로울 수 있다.

3) fixed window counter algorithm
특징:
정해진 시간 구간 동안 허용 임계값 만큼의 요청만 처리하고, 임계값 이상의 요청들은 새로운 시간 구간이 찾아올 때까지 버리는 방식이다.
동작원리는 다음과 같다.
1) 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
2) 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
3) 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

예를 들어, 타임라인의 시간 단위가 1초이고, 초당 3개까지의 요청만이 허용될 때
매 초마다 열리는 윈도에는 3개 이상의 요청이 밀려오면 초과분은 버려진다.
다만, 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다
많은 요청이 처리될 수 있다는 단점이 있다.

장점:
1) 메모리 효율이 좋다.
2) 이해하기 쉽다.
3) 윈도가 닫히는 시점에 카운터를 초기화 하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

단점:
윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

4) sliding window log algorithm
특징:
고정 윈도 카운터 알고리즘에서 지적한 단점을 보완하기 위해 등장한 알고리즘이다.
동작원리는 다음과 같다.
1) 요청의 timestamp를 추적하여 캐시에 보관한다.
2) 새 요청이 오면 만료된 타임스탬프는 제거한다. 
- 여기서 만료된 타임스탬프란 현재 윈도의 시작 시점 보다 그 값이 오래된 타임스탬프를 의미한다.
3) 새 요청의 타임스탬프를 로그에 추가한다.
4) 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.

장점: 어느 순간의 운도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
단점: 거부된 요청의 타임스탬프도 보관하므로, 다량의 메모리가 필요하다.

5) sliding window counter algorithm
특징:
고정 윈도 카운터 알고리즘과 


장점:
단점:

```
